{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a363aa",
   "metadata": {},
   "source": [
    "### Trainieren eines Neurons (Klassifizierung) ![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8df96-5158-406b-a0a8-90078aeddef4",
   "metadata": {},
   "source": [
    "Wir trainieren nun ein Neuron, das 0 f√ºr Mohn und 1 f√ºr Enzian ausgibt.\n",
    "Um den Prozess besser nachvollziehen zu k√∂nnen, lassen wir es zuerst jeweils anhand von je einem Wert auswendig lernen, was Mohn und was Enzian ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1631caa-fcd9-4080-8ce7-02d7b30ad26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy ## um Arrays und Matrizen nutzen zu k√∂nnen\n",
    "\n",
    "\n",
    "## Trainingsdaten\n",
    "\n",
    "breiteMohn = 1.0\n",
    "laengeMohn = 0.9\n",
    "pflanzeM = 0 # Mohn\n",
    "\n",
    "inputMohn = numpy.array([breiteMohn,laengeMohn])\n",
    "target = pflanzeM\n",
    "print(f\"Die einzelnen Merkmalswerte zu dem Tag sind in einer Liste gespeichert: {inputMohn}\")         \n",
    "print(f\"Der Zielwert ist die Pflanzenart (0=Mohn): {target}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3650704",
   "metadata": {},
   "source": [
    "Wenn die Breite 1 ist und die L√§nge 0.9, dann soll das Neuron 0 ausgeben. \n",
    "Dazu m√ºssen die Gewichte die Input-Werte entsprechend anpassen. Es geht also darum, die richtigen Gewichte zu bestimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0064560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Gewichte sind anfangs i.d.R. zuf√§llig festgelegt \n",
    "# Hier sind es feste Zahlenwerte, um reproduzierbare Ergebnisse zu erzielen.\n",
    "weights = numpy.array([0.3, 0.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672b35d9",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    I1((Breite<br>1</br>))\n",
    "    I2((L√§nge<br>0.9</br>))\n",
    "    N1((Pflanze))\n",
    "    I1 --0.3--> N1\n",
    "    I2 --0.5--> N1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36010282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorw√§rtsrechnung Perzeptron, forward propagation (Aktivierungsfunktion: lineare Funktion)\n",
    "# einzelne Rechnungen:\n",
    "output = weights[0] * inputMohn[0]  +  weights[1] * inputMohn[1]\n",
    "print(f\"Erste Sch√§tzung: {output}. Wir erwarten {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293fb3b",
   "metadata": {},
   "source": [
    "Es gibt also noch eine Abweichung vom Erwarteten Wert.\n",
    "Nun bestimmt man den Fehler, der gemacht wurde, um anhand des Fehlers die Gewichte zu korrigieren (R√ºckw√§rtsrechnung, Backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung des Fehlers\n",
    "error = target - output\n",
    "print(f\"Das KI-System hat einen Fehler von {error} gemacht\")\n",
    "# Berechnung des quadratischen Fehlers (quadratisch --> stetiges Minimierungsproblem)\n",
    "# Der Einfachheit halber ist die Fehlerfunktion hier nur f√ºr einen einzelnen Output definiert.\n",
    "MSE = numpy.square(target - output)   \n",
    "print(f\"Die Fehlerfunktion Mean Square Error ergibt {MSE}. Diese soll minimiert werden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14411d50",
   "metadata": {},
   "source": [
    "$ùë°$: true value, tats√§chlicher Wert\n",
    "\n",
    "$ùëú$: Output, Ausgabewert der KI\n",
    "\n",
    "$MSE$: Mittlerer quadratischer Fehler bzw. Mean Squared Error (MSE)\n",
    "\n",
    "$MSE=(ùë°‚àíùëú)^2$\n",
    "\n",
    "Dieser Fehler wird verwendet, um die Gewichte anzupassen.\n",
    "Dazu muss die Ableitung des Fehlers bezogen auf jeweils das Gewicht $w_1$ und $w_2$ bestimmt werden.\n",
    "Diese Ableitung nach einer bestimmten Gr√∂√üe nennt man partielle Ableitung und wird statt mit einem $d$ mit einem $\\partial$ angegeben.\n",
    "\n",
    "Wir berechnen also, um wie viel das Gewicht $w_1$ ver√§ndert werden muss durch:\n",
    "\n",
    "$\\Delta w_0=\\frac{\\partial MSE}{\\partial w_0}=\\frac{\\partial}{\\partial w_0}\\cdot(t-o)^2$\n",
    "\n",
    "nach Anwendung der Kettenregel ergibt das:\n",
    "\n",
    "$\\Delta w_0=2\\cdot(t-o)\\cdot\\frac{\\partial}{\\partial w_0}\\cdot(t-o)$\n",
    "\n",
    "Mit $o=w_0\\cdot i_0 + w_1\\cdot i_1$\n",
    "\n",
    "$\\Delta w_0=2\\cdot(t-o)\\cdot\\frac{\\partial}{\\partial w_0}\\cdot(t- (w_0\\cdot i_0 + w_1\\cdot i_1))$\n",
    "\n",
    "Da wir nur nach $w_1$ ableiten, sind die Beitr√§ge von $w_1$ zum Ouput $o$ egal und werden weggelassen, $w_1\\cdot i_1=0$ f√ºr diesen Fall. \n",
    "\n",
    "Wenn wir die √Ñnderung $\\Delta w_1$ bestimmen, dann muss der Betrag von $w_1$ weggelassen werden, also dann $w_0\\cdot i_0 = 0$.\n",
    "\n",
    "$\\Delta w_0=2\\cdot(t-o)\\cdot (-i_0)$\n",
    "\n",
    "mit $e=t-o$ (kann auch negativ werden) ergibt das\n",
    "\n",
    "$\\Delta w_0=-2\\cdot e\\cdot i_0$\n",
    "\n",
    "Je gr√∂√üer also der Fehler und der Input, desto gr√∂√üer ist die Gewichtsanpassung.\n",
    "\n",
    "Die Berechnung f√ºr $\\Delta w_1$ geht genauso und sparen wir uns daher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412603c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechnung der Ableitung nach dem Gewicht w0\n",
    "dw0 = -2 * inputMohn[0] * error\n",
    "print(f\"Die Ableitung der Fehlerfunktion nach dem Gewicht w0 ergibt: {dw0}.\")\n",
    "# Berechnung der Ableitungen nach den Gewichten w0, w1\n",
    "dw = -2*inputMohn*error\n",
    "print(f\"Alle partiellen Ableitungen der Fehlerfunktion in einem Vektor: {dw}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d36738a",
   "metadata": {},
   "source": [
    "Nun werden die Gewichte entsprechend angepasst:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0595257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gewichte vorher: {weights}\")\n",
    "# Um die Gewichtswerte anzupassen m√ºssen wir sehr kleine Schritte gehen, sonst schie√üen wir √ºber das Ziel hinaus!\n",
    "# Die Lernrate alpha ist ein Hyperparameter, mit dem die Schrittweite angepasst werden kann.\n",
    "alpha = 1e-5    # 1e-5 = 0.000001\n",
    "weights = weights - alpha * dw\n",
    "\n",
    "\n",
    "print(f\"Nach Korrektur:  {weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3be2d6",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    I1((Breite<br>1</br>))\n",
    "    I2((L√§nge<br>0.9</br>))\n",
    "    N1((Pflanze))\n",
    "    I1 --0.299985--> N1\n",
    "    I2 --0.4999865--> N1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorher war der Fehler bei -0.75\n",
    "# Mal sehen wie gro√ü der Fehler nun nach der Anpassung ist!\n",
    "output = numpy.dot(weights, inputMohn)   # das ist das gleiche wie weights[0]*input[0] + weights[1]*input[1], nur als Funktion\n",
    "# Berechnung des Fehlers\n",
    "error = target - output\n",
    "print(f\"Das KI-System hat einen Fehler von {error} gemacht, also ein kleines bisschen besser.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2dce63",
   "metadata": {},
   "source": [
    "Um den Fehler immer weiter zu minimieren, m√ºssen wir den Lernprozess h√§ufiger durchf√ºhren.\n",
    "Dazu brauchen wir noch eine Abbruchbedingung, ab wann und der Fehler klein genug ist.\n",
    "Wir w√§hlen hier willk√ºrlich 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af536008",
   "metadata": {},
   "outputs": [],
   "source": [
    "zaehler = 0  #Z√§hlt die Durchl√§ufe\n",
    "# Wir gehen in einer Schleife viele kleine Schritte, bis wir zu einem zufriedenstellenden Ergebnis gekommen sind.\n",
    "# Hier soll das System lernen, bis der Fehler kleiner 0.01 ist:\n",
    "while abs(error) > 0.01:    # Wird der Sollfehler zu klein eingestellt (z.B. auf 0), kann das im Allgemeinen zu einer Endlosschleife f√ºhren\n",
    "    zaehler += 1\n",
    "    output = numpy.dot(weights, inputMohn)\n",
    "    error = target - output\n",
    "    weights = weights + alpha * 2 * inputMohn * error\n",
    "\n",
    "print(f\"Wir haben {zaehler} Durchl√§ufe ben√∂tigt.\")\n",
    "print(f\"Die Gewichtswerte lauten jetzt {weights}\")\n",
    "print(f\"Der Output ist jetzt {output}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e3cda",
   "metadata": {},
   "source": [
    "Nun hat unser System gelernt, dass bei einem Input von Breite=1 und L√§nge=0.9 es sich um Mohn handelt\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    I1((Breite<br>1</br>))\n",
    "    I2((L√§nge<br>0.9</br>))\n",
    "    N1((Pflanze, <br>0.00999=Mohn</br>))\n",
    "    I1 -- -0.10884009--> N1\n",
    "    I2 --0.13204392--> N1\n",
    "```\n",
    "\n",
    "Was passiert nun, wenn wir ihm Daten von Enzian geben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38812e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "breiteEnzian = 0.3\n",
    "laengeEnzian = 0.7\n",
    "pflanzeE = 1 # Enzian\n",
    "\n",
    "inputEnzian = numpy.array([breiteEnzian, laengeEnzian])\n",
    "\n",
    "output = numpy.dot(weights, inputEnzian)\n",
    "print(f\"Vorhergesagt {output}.\")\n",
    "print(f\"Erwartet haben wir 1.00 (=Enzian).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eed582",
   "metadata": {},
   "source": [
    "Wir m√ºssen also dem Neuron noch beibringen, wann etwas enzian ist.\n",
    "Dazu m√ºssen wir es weiter trainieren.\n",
    "Dazu wechseln wir in der Lernschleife zwischen den beiden Datens√§tzen hin und her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorM = numpy.inf    # Fehler am Anfang unendlich gro√ü\n",
    "errorE = numpy.inf    # Fehler am Anfang unendlich gro√ü\n",
    "alpha = 1e-5           # Hyperparameter Lernrate\n",
    "zaehler = 0            # Z√§hler f√ºr Lernschritte\n",
    "targetM = pflanzeM\n",
    "targetE = pflanzeE\n",
    "\n",
    "while abs(errorM) > 0.01 and abs(errorE) > 0.01:    # Beide Fehler sollen niedrig werden\n",
    "    zaehler += 2\n",
    "    # Ein Lernschritt mit Datensatz input_1\n",
    "    output = numpy.dot(weights, inputMohn)\n",
    "    errorM = targetM - output\n",
    "    weights = weights + alpha * 2 * inputMohn * errorM\n",
    "    # Ein Lernschritt mit Datensatz input_2\n",
    "    output = numpy.dot(weights, inputEnzian)\n",
    "    errorE = targetE - output\n",
    "    weights = weights + alpha * 2 * inputEnzian * errorE\n",
    "\n",
    "\n",
    "print(f\"Wir haben {zaehler} Durchl√§ufe ben√∂tigt.\")\n",
    "print(f\"Die Gewichtswerte lauten jetzt {weights}\\n\")\n",
    "print(f\"F√ºr Mohn {numpy.dot(weights, inputMohn)}.\")\n",
    "print(f\"F√ºr Enzian {numpy.dot(weights, inputEnzian)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088ddaa",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR\n",
    "    I1((Breite<br>1</br>))\n",
    "    I2((L√§nge<br>0.9</br>))\n",
    "    N1((Pflanze))\n",
    "    I1 -- -2.03781097--> N1\n",
    "    I2 --2.2753455--> N1\n",
    "```\n",
    "\n",
    "Nun hat das Neuron die beiden Breiten und L√§ngen f√ºr die beiden Klassen auswendig gelernt.\n",
    "\n",
    "Versuchen wir es auf unbekannte Daten anzuwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten aus NN1.ipynb\n",
    "breiteEnzian = [0.3, 0.9, 0.2, 0.4, 0.6]\n",
    "laengeEnzian = [0.7, 0.2, 0.5, 0.2, 0.3]\n",
    "\n",
    "breiteMohn = [1.0, 0.8, 1.2, 0.6, 1.3]\n",
    "laengeMohn = [0.9, 0.6, 0.5, 0.8, 0.7]\n",
    "\n",
    "inputMNeu = numpy.array([breiteMohn[2],laengeMohn[2]])\n",
    "print(f\"F√ºr unbekannte Mohn-Daten {numpy.dot(weights, inputMNeu)}. Erwartet ist 1 (=Mohn).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a82b3",
   "metadata": {},
   "source": [
    "Das Auswendiglernen der wenigen Daten bringt f√ºr unbekannte Daten nicht viel.\n",
    "\n",
    "Wir m√ºssen das Neuron mit mehr Daten trainieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ddd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = numpy.array([1,1,1,1,1,0,0,0,0,0])  # 5 mal Enzian und dann 5 mal Mohn\n",
    "\n",
    "# Wir m√ºssen nun darauf achten, dass die Input-Daten genau in dieser Reihenfolgen vorliegen\n",
    "\n",
    "input = numpy.array([\n",
    "    [breiteEnzian[0],laengeEnzian[0]],\n",
    "    [breiteEnzian[1],laengeEnzian[1]],\n",
    "    [breiteEnzian[2],laengeEnzian[2]],\n",
    "    [breiteEnzian[3],laengeEnzian[3]],\n",
    "    [breiteEnzian[4],laengeEnzian[4]],\n",
    "    [breiteMohn[0],laengeMohn[0]],\n",
    "    [breiteMohn[1],laengeMohn[1]],\n",
    "    [breiteMohn[2],laengeMohn[2]],\n",
    "    [breiteMohn[3],laengeMohn[3]],\n",
    "    [breiteMohn[4],laengeMohn[4]],\n",
    "    ])\n",
    "\n",
    "\n",
    "print(f\"Der Datensatz in der Zeile 3 lautet beispeilsweise {input[3-1,:]}. Der zugeh√∂rige Zielwert ist {target[3-1]}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea882e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startwerte\n",
    "error = numpy.inf        # Fehler am Anfang unendlich gro√ü\n",
    "alpha = 1e-5             # Hyperparameter Lernrate\n",
    "anzahl_epochen = 200     # Z√§hler f√ºr Lernschritte\n",
    "    \n",
    "for zaehler in range(anzahl_epochen):               # Vorgabe einer festen Anzahl an Epochen f√ºr das Training\n",
    "    for nr in range(len(input)):                    # len(input) gibt die Anzahl der Trainingsdaten an\n",
    "        output = numpy.dot(weights, input[nr,:])    # input[nr,:] sind alle Inputdaten zum Datensatz mit der Zeilennummer 'nr'\n",
    "        error = target[nr] - output                 # target[nr] ist der Zielwert zum Datensatz mit der Nummer 'nr'\n",
    "        weights = weights + alpha * 2 * input[nr,:] * error\n",
    "\n",
    "print(f\"Wir haben {anzahl_epochen} Epochen f√ºr das Training verwendet.\")\n",
    "print(f\"Die Gewichtswerte lauten jetzt {numpy.round(weights,3)}\\n\")\n",
    "print(f\"F√ºr Enzian {numpy.dot(weights, input[0,:])}. Tats√§chlich soll es {target[0]} sein.\")\n",
    "print(f\"F√ºr Mohn {numpy.dot(weights, input[1,:])}. Tats√§chlich soll es {target[-1]} sein.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d28190",
   "metadata": {},
   "source": [
    "Nur ein Neuron kann reicht nicht aus. Wir brauchen mehr Neuronen, die wir zu einem Neuronalen Netz vernetzen.\n",
    "\n",
    "Dazu gibt es fertige Bibliotheken, wie z.B. tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orange3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
